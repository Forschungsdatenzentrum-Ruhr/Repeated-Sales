######################
#Package Install Function
######################
#rerun this if packages are changed/missing
#stuff needs to be hard installed for it to be available to parallel

# packages_install = function(library_string){
#   if (!require("librarian")) install.packages("librarian")
#   librarian::shelf(library_string)
#   print("Packages fully installed and loaded")
# }
# 
# packages_install(pipeline_library)
# 
# for(package in 1:length(pipeline_library)){
#   install.packages(pipeline_library[package])
# }

######################
#Package Install and Load
######################
#used during setup of pipeline
library(targets)
library(tarchetypes)
library(future)
library(future.callr)
library(fst)
library(vctrs)

#used during execution of pipeline
pipeline_library = c(
  "here", # creating dynamic paths based on script location
  "haven", # reading/writing of dta files
  "tidyverse", # data manipulation/wrangeling
  "magrittr", #two sided pipe
  "fst" # logging utilites
)

######################
#Options and parallel
######################

# Set target options:
tar_option_set(
  resources = tar_resources(
    fst = tar_resources_fst(compress = 100)
  ),
  packages = pipeline_library
)

# tar_make_clustermq() configuration (okay to leave alone):
#options(clustermq.scheduler = "multiprocess")

# tar_make_future() configuration:
plan(callr)

######################
#Sourcing
######################

# Load the R scripts with your custom functions:
lapply(list.files("R", full.names = TRUE, recursive = TRUE), source)

######################
#Pipeline
######################

blid_targets = tar_map(
  values = list(.bl_id = 1:1),
  tar_fst_tbl(bl, load_data(filename, bl_id = .bl_id )),
  tar_group_by(group, bl, latlon_utm, balkon),
  tar_fst_tbl(classification, classify_data(group), pattern = map(group))
)

# Replace the target list below with your own:
list(
  tar_target(filename, construct_file_name("v6","Wk"),format = "file"),
  blid_targets
)

# ?tar_group_by
# tar_target(latlon_utm, split_data(data)),
# tar_group_by(classification, classify_data(latlon_utm),groups)









