# TODO:
# use formatting of pop-forecast
# swap away from %>% ?
# add packagename before functions
# use dtplyr
# cluster around each baseline?



######################
# Package Install and Load
######################
# stuff needs to be hard installed for it to be available to parallel
# there has to be a better way to do this

# used during setup of pipeline
req_library <- c(
  "targets",
  "tarchetypes",
  "future",
  "future.callr",
  "fst",
  "renv",
  "rlang",
  "styler",
  "docstring"
)

# used during execution of pipeline
pipeline_library <- c(
  "here",
  "stringr",
  "dplyr",
  "tidyr",
  "data.table",
  "cli",
  "glue",
  "ggplot2",
  "haven", # reading/writing of dta files
  "tidyverse", # data manipulation/wrangeling
  "magrittr", # two sided pipe
  "fst" #
)

suppressPackageStartupMessages({
  # used during setup of pipeline
  library(targets)
  library(tarchetypes)
  library(future)
  library(future.callr)
  library(fst)
  library(renv)
  library(rlang)
  library(styler)
  library(docstring)

  # used during execution of pipeline
  library(here)
  library(stringr)
  library(dplyr)
  library(tidyr)
  library(data.table)
  library(cli)
  library(glue)
  library(ggplot2)
  library(haven)
  library(magrittr)
})


######################
# Options and parallel
######################
# Set target options:
tar_option_set(
  resources = tar_resources(
    fst = tar_resources_fst(compress = 100)
  ),
  packages = pipeline_library
)

# tar_make_future() configuration:
plan(callr)

# script settings
range_offsets <<- tibble::tribble(
  ~categorie, ~resembling_offset, ~exact_offset, ~offset_type,
  "wohnflaeche", 0.1, 0.05, "multi",
  "etage", 99, 0, "add",
  "zimmeranzahl", 0.5, 0, "add",
  "time", 0, 6, NA
)
# extract time offset for readability
time_offset <- range_offsets$exact_offset[range_offsets$rowname == "time"]



######################
# Sourcing
######################
# Load the R scripts with your custom functions:
lapply(list.files("R", full.names = TRUE, recursive = TRUE), source)

######################
# Pipeline
######################

## create targets for each federal states
federal_state_targets <- tar_map(

  # federal state static ids
  values = list(.federal_state_id = 1:1),

  # load data, do basic cleaning
  tar_fst_tbl(
    federal_state,
    load_data(
      file_name = file_name,
      federal_state_id = .federal_state_id
    )
  ),

  # group data by zip code
  # this could be any group larger than lat+lon
  # smaller granularity leads to more intermediary files and therefore scaling issues
  tar_group_by(
    plz_group,
    federal_state,
    plz
  ),

  # classify data
  tar_fst_tbl(
    classification,
    classify_data(
      geo_grouped_data = plz_group
    ),
    pattern = map(plz_group)
  )
)

## combine to main pipeline
list(
  # generates file_name used, version and type can be specified
  tar_file(
    file_name,
    construct_file_name(
      data_version = "v6",
      data_type = "Wk"
    )
  ),

  # federal state targets
  federal_state_targets,

  # combine last step of federal state targets together into single output
  tar_combine(
    repeated,
    federal_state_targets[[length(federal_state_targets)]],
    command = bind_rows(!!!.x),
    format = "fst_tbl"
  )
)
