---
title: "Repeated sales/rent walkthrough"
output:
  pdf_document: default
  html_document:
    code_folding: show
    theme:
      bg: '#202123'
      fg: '#B8BCC2'
      primary: '#EA80FC'
      secondary: '#00DAC6'
      base_font:
        google: Prompt
      heading_font:
        google: Proza Libre
---
THIS FILE ONLY COMPILES DURING THE PIPELINE; ERRORS IF DONE MANUALLY!
Introduction outlining the idea and process..

Details of reading/reprocessing the RED data can be found in R/read_/, specifically read_RED.R and prepare_RED.R. These should be self explanatory. Note that the classification algorithm is designed to be run in parallel.^[I recommend using 'tar_make_future(workers = n)', where $n$ is the number of cores. $n = 4$ is a decent value, when no one else is using the server the number can be set higher. More than 8 is overkill, since Berlin alone typically bottlenecks. If speed becomes a big issue with growing data consider using "foreach()" on the coordinate level.] This is achieved by grouping the RED data on "blid", i.e. one group for each federal state. These groups are than classified in parallel for significant speedups. This classification digs down to coordinate-level, which is where i will start explaining the actual procedure. 

Also dropped filtered and dropped balkon---
The example data is taken from a coordinate with $25$ observations of federal state Bremen. Since the data is already subset to the required dissolution for the next steps, the variables "blid" and "latlon_utm" were dropped beforehand (See R/misc/make_example_markdown_data.R for details).

```{r}
## load example data
tar_load(example_markdown_data)
#make this dynamic
#tar_load(example_markdown_data, store ="N:/FDZ/Intern/HiWi-Praktikanten/Mitarbeiter/Thorben/repeated offerings/_targets")
```

#General makeup of the data:
```{r}
# show head
head(example_markdown_data)
# show summary
summary(example_markdown_data)
```

There are two types of similarity which will be considered: resembling and exact. The former allows for slightly larger deviations, the latter is quite restrictive. "r_o" refers to resembeling offset and "e_o" to exact offset.

# parameter used for classification:
```{r}
# these are globally defined in _targets.R
print(exportJSON)
```

```{r}
# make color blind friendly palette
etage_colors = MetBrewer::met.brewer("Egypt", n = length(example_markdown_data$etage))
with(
  example_markdown_data,
  scatterplot3d(x = wohnflaeche , y = zimmeranzahl, z =  etage , color = etage_colors, pch = 16)
)

```
Note that direct overlaps naturally arent visible. The challenge now is to make a decision: are the lisings for two different apartments or are they the same apartment? To make this decision for any number of characteristic combinations, I use a modified version of k-nearest neighbors clustering. Before we can get to this stage however, it is necessary to define and approach the issue formally. Visually classifying each combination at each coordinate would take quite some time (and would have to be re-done for every new wave, more on that later).

We will proceed in two overarching dimensions: the characteristics dimension (classifying similarity) and the subsequent time dimension ('classifying' non list reason): 


# characteristics dimension


```{r}
# save ordering of ids
occurence_ids <- example_markdown_data[, counting_id]

similarity_lists = make_similarity_lists(example_markdown_data,occurence_ids)
```
# index 
```{r}
similarity_index_list = similarity_lists[[1]]
similarity_index_list[1:5,1:5]
```
# similarity distances
```{r}
similarity_dist_list = similarity_lists[[2]]
similarity_dist_list[1:5,1:5]
```

```{r}
    similarity_dist_list[is.na(similarity_index_list)] = NA
      
    # setup and run the actual clustering
    clustering <- cluster$new(
      cluster_options = similarity_index_list,
      distance = similarity_dist_list
    )
    clustering$determine_cluster_centers()
    clustering$centers |> head(n = 10)
```
```{r}
clustering$centers <- clustering$centers[
        ,
        similarity_cost_function(.SD)
      ]
clustering$centers |>  head(n = 10)
```

```{r}
out <- geo_grouped_data[
    clustering$centers,
    on = .(counting_id)
  ]
out |>  head(n = 10)
```

