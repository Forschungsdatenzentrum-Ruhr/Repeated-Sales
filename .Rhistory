),
on = .(parent == counting_id)
]
gains_comparison
child_parent_competitors
# split gain-winners into parent-/child type since they cause each
# have different consequences
winner_ids <- split(gains_comparison, by = "winner_type", keep.by = F)
winner_ids
# all parent-type winners eliminate them being a child of someone else
# NOTE This should be possible in one join but i cant find a way to
# add the latter select into the on statement
child_removal <- competing_parents[
.(winner_ids$parent),
on = .(counting_id = counting_id)
][!parent == counting_id]
child_removal
parent_children_ids
parent_children_competitors
## first option: x parent of cluster x with children y_n -> gain = sum(similiarity of children)
# isolate competitors based on ids
parent_children_competitors <- unique_clustering_centers[
.(parent_children_ids),
on = "parent"
]
# calculate gains of being x being a parent
parent_gains <- parent_children_competitors[
,
.("cluster_sim_dist" = mean(sim_dist)),
by = "parent",
]
parent_gains
## second option: x child of cluster z -> gain = similarity to parent
# isolate competitors based on ids
child_parent_competitors <- unique_clustering_centers[
.(parent_children_ids),
on = "counting_id"
]
child_gains <- child_parent_competitors[
counting_id != parent,
.("counting_id" = counting_id, "single_sim_dist" = sim_dist),
]
child_gains
# Compare gains and choose lower sim_dist (more similiarity gained)
gains_comparison <- parent_gains[
child_gains,
.(
"counting_id" = counting_id,
"winner_type" = fifelse(
cluster_sim_dist >= single_sim_dist, "child", "parent"
)
),
on = .(parent == counting_id)
]
gains_comparison
winner_ids <- split(gains_comparison, by = "winner_type", keep.by = F)
# Unit-Test
# Check if any ids have been assigned as both parent and child winner
tar_assert_true(
!any(winner_ids$child %in% winner_ids$parent),
msg = winner_ids
)
# all parent-type winners eliminate them being a child of someone else
# NOTE This should be possible in one join but i cant find a way to
# add the latter select into the on statement
child_removal <- competing_parents[
.(winner_ids$parent),
on = .(counting_id = counting_id)
][!parent == counting_id]
child_removal
parent_gains
parent_children_competitors
gains_comparison
child_gains
parent_gains
child_gains
parent_gains
parent_children_competitors
parent_gains
child_gains
# calculate gains of being x being a parent
parent_gains <- parent_children_competitors[
,
.("cluster_sim_dist" = sum(sim_dist)), #mean(sim_dist)),
by = "parent",
]
parent_gains
child_parent_competitors
child_parent_competitors
child_gains
# Compare gains and choose lower sim_dist (more similiarity gained)
# this can have conflicting outcomes -> ISSUE
# children chose each other as their parent -> stronger rule?
# maybe remove best gains and apply recursively?
gains_comparison <- parent_gains[
child_gains,
.(
"counting_id" = counting_id,
"winner_type" = fifelse(
cluster_sim_dist >= single_sim_dist, "child", "parent"
)
),
on = .(parent == counting_id)
]
gains_comparison
tar_make()
tar_make_future(workers = 3)
tar_load(WM_classified)
tar_load(WM_classification)
tar_load(WM_full_data)
# find all columns that are present in both, classification columns take precedence
# disregarding counting_id, since this is used for the merge
names_diff <- setdiff(intersect(names(classification), names(RED_full_data)), "counting_id")
# remove columns from RED and merge classifcation
RED_classified <- RED_full_data[, !..names_diff][classification, on = "counting_id"]
classification = WK_classification
classification = WM_classification
RED_full_data = WM_full_data
rm(WM_full_data)
rm(WM_classification)
# find all columns that are present in both, classification columns take precedence
# disregarding counting_id, since this is used for the merge
names_diff <- setdiff(intersect(names(classification), names(RED_full_data)), "counting_id")
# remove columns from RED and merge classifcation
RED_classified <- RED_full_data[, !..names_diff][classification, on = "counting_id"]
check_geo = RED_classified[,uniqueN(latlon_utm) == 1 & uniqueN(kid2019) == 1 , by = "parent"]
tar_assert_true(all(check_geo[[2]]), msg = glue::glue("Double geo ids found for: {RED_classified[check_geo[[2]]]})
# subset to 15 biggest cities
big_fifteen = c(
"11000000", # Berlin
"02000000", # Hamburg
"09162000", # München
"05315000", # Köln
"06412000", # Frankfurt
"08111000", # Stuttgart
"05111000", # Düsseldorf
"14713000", # Leipzig
"05913000", # Dortmund
"05113000", # Essen
"04011000", # Bremen
"14612000", # Dresden
"03241001", # Hannover
"09564000", # Nürnberg
"05112000"  # Duisburg
) |> as.numeric()
RED_classified = RED_classified[gid2019 %in% big_fifteen]
return(RED_classified)
}
tar_assert_true(all(check_geo[[2]]), msg = glue::glue("Double geo ids found for: {RED_classified[check_geo[[2]]]}")
# subset to 15 biggest cities
big_fifteen = c(
"11000000", # Berlin
"02000000", # Hamburg
"09162000", # München
"05315000", # Köln
"06412000", # Frankfurt
"08111000", # Stuttgart
"05111000", # Düsseldorf
"14713000", # Leipzig
"05913000", # Dortmund
"05113000", # Essen
"04011000", # Bremen
"14612000", # Dresden
"03241001", # Hannover
"09564000", # Nürnberg
"05112000"  # Duisburg
) |> as.numeric()
RED_classified = RED_classified[gid2019 %in% big_fifteen]
return(RED_classified)
}
tar_assert_true(all(check_geo[[2]], msg = glue::glue("Double geo ids found for: {RED_classified[check_geo[[2]]]}")
,
))
tar_assert_true(all(check_geo[[2]], msg = glue::glue("Double geo ids found for: {RED_classified[check_geo[[2]]]}"))
# subset to 15 biggest cities
big_fifteen = c(
"11000000", # Berlin
"02000000", # Hamburg
"09162000", # München
"05315000", # Köln
"06412000", # Frankfurt
"08111000", # Stuttgart
"05111000", # Düsseldorf
"14713000", # Leipzig
"05913000", # Dortmund
"05113000", # Essen
"04011000", # Bremen
"14612000", # Dresden
"03241001", # Hannover
"09564000", # Nürnberg
"05112000"  # Duisburg
) |> as.numeric()
RED_classified = RED_classified[gid2019 %in% big_fifteen]
return(RED_classified)
}
tar_assert_true(all(check_geo[[2]], msg = glue::glue("Double geo ids found for: {RED_classified[check_geo[[2]]]}")))
tar_assert_true(all(check_geo[[2]], msg = glue::glue("Double geo ids found for: {RED_classified[check_geo[[2]], by = parent]}")))
head(check_geo)
table(check_geo$V1)
# check if everything that has been classified didnt move in geo ids
check_geo = RED_classified[,check_complete = uniqueN(latlon_utm) == 1 & uniqueN(kid2019) == 1 , by = "parent"]
# check if everything that has been classified didnt move in geo ids
check_geo = RED_classified[,.(check_complete = uniqueN(latlon_utm) == 1 & uniqueN(kid2019) == 1) , by = "parent"]
tar_assert_true(all(check_geo[[2]], msg = glue::glue("Double geo ids found for: {check_geo[check_complete == FALSE]}")))
glue::glue("Double geo ids found for: {check_geo[check_complete == FALSE]}")
glue::glue("Double geo ids found for: {check_geo[check_complete == FALSE, parent]}")
RED_classified[parent=="21699113"]
tst = RED_classified[parent=="21699113"]
View(tst)
base::gc()
tar_make()
tar_load(split_index)
tar_load(WK_split_index)
View(WK_split_index)
View(WK_split_index)
tar_load(WK_hybrid_index)
head(WK_hybrid_index)
tar_load(c("WK_classified","WK_prepared_repeated"))
data_type = "WK"
RED_classified = WK_classified
tar_load(WK_classified)
tar_load(WK_classifed)
RED_classified = WK_classifed
rm(WK_classifed)
library(styler)
tar_load_globals()
list_var = make_var(data_type = data_type)
indepVar = list_var$indepVar
depVar = list_var$depVar
# think of a solution for this, they are mutated in prepare_hedonic
var_to_keep = c(indepVar,"rs_id","emonths","depVar","rs_id","counting_id")
# one consideration is that we have to decide between using or dropping updates from hedonic as well
# build by me based on Case and Quigley 1991
# get ids of all listings that are classified as repeat sales (pure or changed)
all_rs = prepared_repeated[["rs_id"]] |> unique()
# split into repeat and hedonic
RED_classified = prepare_hedonic(RED_classified, data_type)[,":="(
hybrid_type = fifelse(rs_id %in% all_rs, "repeat", "hedonic"),
depVar = exp(get(depVar))
)
]
# to split repeat into pure and changed, figure out which listings have changed within id
# this means however that between pairs quality changed, so for that listing pair
# reduce listings to only repeats and set missings to zero
pure_rs = RED_classified[
hybrid_type == "repeat",
..var_to_keep
]
changed_boolean = pure_rs[,
lapply(.SD, function(x){c(NA,diff(x))}),
by = rs_id,
.SDcols = setdiff(var_to_keep,c("rs_id","emonths","depVar","counting_id"))
][,rs_id := NULL] |> rowSums() != 0
is.na(changed_boolean) = FALSE
tar_assert_true(length(changed_boolean) == nrow(pure_rs))
pure_rs[, changed_to := changed_boolean][, changed_from := lead(changed_to,1), by = rs_id]
binary_names = c("balkon","garten","einbaukueche","gaestewc","aufzug","keller","betreut","ausstattung","declared_wohngeld", "baujahr_cat", "first_occupancy", "num_floors", "floors_cat")
cont_names = c("zimmeranzahl")
# this pretty much allows for duplicate indiviudal listings between pure/changed
# sample 1 pure rs
pure_pairs = pure_rs[changed_to == FALSE | changed_from == FALSE]
# sample 2 quality changed rs
changed_pairs = pure_rs[changed_to == TRUE | changed_from == TRUE]
# smaple 3 hedonic
hedonic_listings = RED_classified[hybrid_type == "hedonic", ..var_to_keep]
# type specific setups, mostly for readability
# this is incredibly ugly, refactor it later
# hedonic
hedonic_V = hedonic_listings[["depVar"]]
hedonic_t_month = hedonic_listings[["emonths"]]
hedonic_counting_id = hedonic_listings[["counting_id"]]
# pure
pure_V_t = pure_pairs[["depVar"]]
pure_V_T = pure_pairs[,lag(depVar,1), by = "rs_id"][,rs_id := NULL][["V1"]]
pure_t_month = pure_pairs[["emonths"]]
pure_T_month = pure_pairs[,lag(emonths,1), by = "rs_id"][,rs_id := NULL][["V1"]]
pure_counting_id = pure_pairs[["counting_id"]]
# changed
changed_V_t = changed_pairs[["depVar"]]
changed_V_T = changed_pairs[,lag(depVar,1), by = "rs_id"][,rs_id := NULL][["V1"]]
changed_t_month = changed_pairs[["emonths"]]
changed_T_month = changed_pairs[,lag(emonths,1), by = "rs_id"][,rs_id := NULL][["V1"]]
changed_counting_id = changed_pairs[["counting_id"]]
Z = do.call(rbind, list(
# hedonic
X_1 = make_X_1(hedonic = hedonic_listings, x_conts = cont_names, x_binaries = binary_names, t_month = hedonic_t_month),
# pure
X_2 = make_X_2(pure = pure_pairs, x_conts = cont_names, x_binaries = binary_names, t_month = pure_t_month, T_month = pure_T_month),
# changed
X_3 = make_X_3(
changed = changed_pairs,
x_conts = cont_names,
x_binaries = binary_names,
t_month = changed_t_month,
T_month = changed_T_month
)
))
Y = log(
c(
hedonic_V,
(pure_V_t/pure_V_T),
(changed_V_t/changed_V_T)
)
)
combined_hybrid = cbind(Z,Y)[,counting_id := c(hedonic_counting_id, pure_counting_id, changed_counting_id)] |> na.omit()
# final clean up -> these shouldnt really happend beforehand
combined_hybrid = combined_hybrid[pre_zimmeranzahl != -Inf & sub_zimmeranzahl != -Inf & Y > 0]
f <- sprintf("%s ~ %s",
"Y",
names(Z) |> paste(collapse = " + ")
) |> as.formula()
hybrid_regression = feols(f, combined_hybrid, combine.quick = F, mem.clean = T)
prepare_hedonic = WK_prepared_repeated
list_var = make_var(data_type = data_type)
indepVar = list_var$indepVar
depVar = list_var$depVar
# think of a solution for this, they are mutated in prepare_hedonic
var_to_keep = c(indepVar,"rs_id","emonths","depVar","rs_id","counting_id")
# one consideration is that we have to decide between using or dropping updates from hedonic as well
# build by me based on Case and Quigley 1991
# get ids of all listings that are classified as repeat sales (pure or changed)
all_rs = prepared_repeated[["rs_id"]] |> unique()
# split into repeat and hedonic
RED_classified = prepare_hedonic(RED_classified, data_type)[,":="(
hybrid_type = fifelse(rs_id %in% all_rs, "repeat", "hedonic"),
depVar = exp(get(depVar))
)
]
# to split repeat into pure and changed, figure out which listings have changed within id
# this means however that between pairs quality changed, so for that listing pair
# reduce listings to only repeats and set missings to zero
pure_rs = RED_classified[
hybrid_type == "repeat",
..var_to_keep
]
changed_boolean = pure_rs[,
lapply(.SD, function(x){c(NA,diff(x))}),
by = rs_id,
.SDcols = setdiff(var_to_keep,c("rs_id","emonths","depVar","counting_id"))
][,rs_id := NULL] |> rowSums() != 0
is.na(changed_boolean) = FALSE
tar_assert_true(length(changed_boolean) == nrow(pure_rs))
pure_rs[, changed_to := changed_boolean][, changed_from := lead(changed_to,1), by = rs_id]
binary_names = c("balkon","garten","einbaukueche","gaestewc","aufzug","keller","betreut","ausstattung","declared_wohngeld", "baujahr_cat", "first_occupancy", "num_floors", "floors_cat")
cont_names = c("zimmeranzahl")
# this pretty much allows for duplicate indiviudal listings between pure/changed
# sample 1 pure rs
pure_pairs = pure_rs[changed_to == FALSE | changed_from == FALSE]
# sample 2 quality changed rs
changed_pairs = pure_rs[changed_to == TRUE | changed_from == TRUE]
# smaple 3 hedonic
hedonic_listings = RED_classified[hybrid_type == "hedonic", ..var_to_keep]
# type specific setups, mostly for readability
# this is incredibly ugly, refactor it later
# hedonic
hedonic_V = hedonic_listings[["depVar"]]
hedonic_t_month = hedonic_listings[["emonths"]]
hedonic_counting_id = hedonic_listings[["counting_id"]]
# pure
pure_V_t = pure_pairs[["depVar"]]
pure_V_T = pure_pairs[,lag(depVar,1), by = "rs_id"][,rs_id := NULL][["V1"]]
pure_t_month = pure_pairs[["emonths"]]
pure_T_month = pure_pairs[,lag(emonths,1), by = "rs_id"][,rs_id := NULL][["V1"]]
pure_counting_id = pure_pairs[["counting_id"]]
# changed
changed_V_t = changed_pairs[["depVar"]]
changed_V_T = changed_pairs[,lag(depVar,1), by = "rs_id"][,rs_id := NULL][["V1"]]
changed_t_month = changed_pairs[["emonths"]]
changed_T_month = changed_pairs[,lag(emonths,1), by = "rs_id"][,rs_id := NULL][["V1"]]
changed_counting_id = changed_pairs[["counting_id"]]
Z = do.call(rbind, list(
# hedonic
X_1 = make_X_1(hedonic = hedonic_listings, x_conts = cont_names, x_binaries = binary_names, t_month = hedonic_t_month),
# pure
X_2 = make_X_2(pure = pure_pairs, x_conts = cont_names, x_binaries = binary_names, t_month = pure_t_month, T_month = pure_T_month),
# changed
X_3 = make_X_3(
changed = changed_pairs,
x_conts = cont_names,
x_binaries = binary_names,
t_month = changed_t_month,
T_month = changed_T_month
)
))
Y = log(
c(
hedonic_V,
(pure_V_t/pure_V_T),
(changed_V_t/changed_V_T)
)
)
combined_hybrid = cbind(Z,Y)[,counting_id := c(hedonic_counting_id, pure_counting_id, changed_counting_id)] |> na.omit()
# final clean up -> these shouldnt really happend beforehand
combined_hybrid = combined_hybrid[pre_zimmeranzahl != -Inf & sub_zimmeranzahl != -Inf & Y > 0]
f <- sprintf("%s ~ %s",
"Y",
names(Z) |> paste(collapse = " + ")
) |> as.formula()
hybrid_regression = feols(f, combined_hybrid, combine.quick = F, mem.clean = T)
list_var = make_var(data_type = data_type)
indepVar = list_var$indepVar
depVar = list_var$depVar
# think of a solution for this, they are mutated in prepare_hedonic
var_to_keep = c(indepVar,"rs_id","emonths","depVar","rs_id","counting_id")
# build by me based on Case and Quigley 1991
# get ids of all listings that are classified as repeat sales (pure or changed)
all_rs = prepared_repeated[["rs_id"]] |> unique()
prepared_repeated = WK_prepared_repeated
# build by me based on Case and Quigley 1991
# get ids of all listings that are classified as repeat sales (pure or changed)
all_rs = prepared_repeated[["rs_id"]] |> unique()
# split into repeat and hedonic
RED_classified = prepare_hedonic(RED_classified, data_type)[,":="(
hybrid_type = fifelse(rs_id %in% all_rs, "repeat", "hedonic"),
depVar = exp(get(depVar))
)
]
tar_load_globals()
# split into repeat and hedonic
RED_classified = prepare_hedonic(RED_classified, data_type)[,":="(
hybrid_type = fifelse(rs_id %in% all_rs, "repeat", "hedonic"),
depVar = exp(get(depVar))
)
]
# reduce listings to only repeats and set missings to zero
pure_rs = RED_classified[
hybrid_type == "repeat",
..var_to_keep
]
changed_boolean = pure_rs[,
lapply(.SD, function(x){c(NA,diff(x))}),
by = rs_id,
.SDcols = setdiff(var_to_keep,c("rs_id","emonths","depVar","counting_id"))
][,rs_id := NULL] |> rowSums() != 0
is.na(changed_boolean) = FALSE
tar_assert_true(length(changed_boolean) == nrow(pure_rs))
pure_rs[, changed_to := changed_boolean][, changed_from := lead(changed_to,1), by = rs_id]
binary_names = c("balkon","garten","einbaukueche","gaestewc","aufzug","keller","betreut","ausstattung","declared_wohngeld", "baujahr_cat", "first_occupancy", "num_floors", "floors_cat")
cont_names = c("zimmeranzahl")
# this pretty much allows for duplicate indiviudal listings between pure/changed
# sample 1 pure rs
pure_pairs = pure_rs[changed_to == FALSE | changed_from == FALSE]
# sample 2 quality changed rs
changed_pairs = pure_rs[changed_to == TRUE | changed_from == TRUE]
# smaple 3 hedonic
hedonic_listings = RED_classified[hybrid_type == "hedonic", ..var_to_keep]
# type specific setups, mostly for readability
# this is incredibly ugly, refactor it later
# hedonic
hedonic_V = hedonic_listings[["depVar"]]
hedonic_t_month = hedonic_listings[["emonths"]]
hedonic_counting_id = hedonic_listings[["counting_id"]]
# pure
pure_V_t = pure_pairs[["depVar"]]
pure_V_T = pure_pairs[,lag(depVar,1), by = "rs_id"][,rs_id := NULL][["V1"]]
pure_t_month = pure_pairs[["emonths"]]
pure_T_month = pure_pairs[,lag(emonths,1), by = "rs_id"][,rs_id := NULL][["V1"]]
pure_counting_id = pure_pairs[["counting_id"]]
# changed
changed_V_t = changed_pairs[["depVar"]]
changed_V_T = changed_pairs[,lag(depVar,1), by = "rs_id"][,rs_id := NULL][["V1"]]
changed_t_month = changed_pairs[["emonths"]]
changed_T_month = changed_pairs[,lag(emonths,1), by = "rs_id"][,rs_id := NULL][["V1"]]
changed_counting_id = changed_pairs[["counting_id"]]
Z = do.call(rbind, list(
# hedonic
X_1 = make_X_1(hedonic = hedonic_listings, x_conts = cont_names, x_binaries = binary_names, t_month = hedonic_t_month),
# pure
X_2 = make_X_2(pure = pure_pairs, x_conts = cont_names, x_binaries = binary_names, t_month = pure_t_month, T_month = pure_T_month),
# changed
X_3 = make_X_3(
changed = changed_pairs,
x_conts = cont_names,
x_binaries = binary_names,
t_month = changed_t_month,
T_month = changed_T_month
)
))
Y = log(
c(
hedonic_V,
(pure_V_t/pure_V_T),
(changed_V_t/changed_V_T)
)
)
combined_hybrid = cbind(Z,Y)[,counting_id := c(hedonic_counting_id, pure_counting_id, changed_counting_id)] |> na.omit()
# final clean up -> these shouldnt really happend beforehand
combined_hybrid = combined_hybrid[pre_zimmeranzahl != -Inf & sub_zimmeranzahl != -Inf & Y > 0]
f <- sprintf("%s ~ %s",
"Y",
names(Z) |> paste(collapse = " + ")
) |> as.formula()
hybrid_regression = feols(f, combined_hybrid, combine.quick = F, mem.clean = T)
summary(hybrid_regression)
pindex = mean(hybrid_regression$sumFE)
hybrid_regression$sumFE
tst= summary(hybrid_regression)
# remerge fixed effects
combined_hybrid = combined_hybrid[RED_classified[,.SD,.SDcols = c(fixed_effects,"counting_id")], on = "counting_id"]
# remerge fixed effects
combined_hybrid = combined_hybrid[RED_classified[,.SD,.SDcols = c(get(fixed_effects),"counting_id")], on = "counting_id"]
# remerge fixed effects
var_to_keep = c(fixed_effects,"counting_id")
combined_hybrid = combined_hybrid[RED_classified[,.SD,.SDcols = var_to_keep], on = "counting_id"]
fixed_effects
# FE attempt
fixed_effects = list_var$fixed_effects
# remerge fixed effects
var_to_keep = c(fixed_effects,"counting_id")
combined_hybrid = combined_hybrid[RED_classified[,.SD,.SDcols = var_to_keep], on = "counting_id"]
combined_hybrid
base::gc()
