!"Miss",
c("start_position", "end_position") := which_range(non_list_reason),
on = "non_list_reason"
][
,
# can calculate something like price difference from initial offering to actual sale price
amonths := fifelse(
!start_position == end_position & !is.na(start_position),
amonths[start_position],
amonths
)
]
parent_grouped_data_connected[, c("start_position","end_position") := NULL]
# check if no NAs were created somewhere
tar_assert_true(!parent_grouped_data_connected[,anyNA(.SD), .SDcols = c("non_list_reason","non_list_duration")])
return(parent_grouped_data_connected)
# parent_grouped_data
}
# .SDcols = c("amonths","emonths")
geo_grouped_data_connected <- geo_grouped_data_similarity[,
{
custom_progress_bar("Connected", .GRP, .NGRP);
non_list_classification(.SD, data_end_date)
},
by = parent
]
View(geo_grouped_data_connected)
Sys.date()
Sys.Date()
# time offset for readability
time_offset <- fcase(
RED_type == "WM", 3,
RED_type %in% c("WK","HK"), 6
)
tar_make_future(reporter = "timestamp", workers = 4)
tar_load_globals()
# Paths -------------------------------------------------------------------
curr_date = Sys.Date() |> str_replace_all("-","_")
tar_make_future(reporter = "timestamp", workers = 4)
?seq
seq(0,0.05)
# plot_offset
wohnflaeche_range = c(
0:0.05
)
# plot_offset
wohnflaeche_range = c(
seq_along(0.05)
)
seq_along(0.05)
seq(from = 0, to = 0.05, by = 0.01)
# plot_offset
low_cutoff = 0.1
high_cutoff = 1
wohnflaeche_range = c(
seq(from = 0, to = low_cutoff, by = 0.01),
seq(from = low_cutoff, to = high_cutoff, by = 0.1)
)
wohnflaeche_range
wohnflaeche_range = c(
seq(from = 0, to = low_cutoff, by = 0.01),
seq(from = low_cutoff, to = high_cutoff, by = 0.1)
) |> unique()
wohnflaeche_range
base::gc()
library(styler)
renv::rebuild("styler")
styler:::style_active_file()
styler:::style_active_file()
wohnflaeche_eo_range = c(
seq(from = 0, to = low_cutoff, by = 0.01),
seq(from = low_cutoff, to = high_cutoff, by = 0.1)
) |> unique()
wohnflaeche_ro_range = shift(wohnflaeche_eo_range)
wohnflaeche_ro_range = c(
seq(from = 0, to = low_cutoff, by = 0.01),
seq(from = low_cutoff, to = high_cutoff, by = 0.1)
) |> unique()
wohnflaeche_eo_range = shift(wohnflaeche_eo_range)
wohnflaeche_eo_range
wohnflaeche_eo_range = shift(wohnflaeche_ro_range)
wohnflaeche_ro_range = c(
seq(from = 0, to = low_cutoff, by = 0.01),
seq(from = low_cutoff, to = high_cutoff, by = 0.1)
) |> unique()
wohnflaeche_ro_range
wohnflaeche_eo_range
wohnflaeche_eo_range = wohnflaeche_eo_range[-1]
wohnflaeche_ro_range = wohnflaeche_ro_range[-1]
values = rlang::list2(
resembling_offset = wohnflaeche_ro_range,
exact_offset = wohnflaeche_eo_range,
non_list_reason_sensitivity = glue::glue("non_list_reason_{exact_offset}")
)
# ###########################################################################
# # FEDERALSTATE_TARGETS -------------------------------------------------------------
# ###########################################################################
#
## create targets for each federal states
federal_state_targets <- rlang::list2(
#this seems slightly slower than prior usage of tar_group_by + pattern(map)
# usage of pattern causes hash names however which makes loading difficult
# classify data
tar_eval(
tar_fst_dt(
classification_ids,
make_classification(
geo_grouped_data = RED[.(federal_state_ids), on = "blid"]
)
),
values = rlang::list2(
federal_state_ids = federal_state_ids,
classification_ids = classification_ids
)
),
tar_eval(
tar_fst_dt(
non_list_reason_sensitivity,
make_sensitivity(
geo_grouped_data = RED[.(4), on = "blid"],
)
),
values = rlang::list2(
resembling_offset = wohnflaeche_ro_range,
exact_offset = wohnflaeche_eo_range,
non_list_reason_sensitivity = glue::glue("non_list_reason_{!!exact_offset}")
)
)
)
values = rlang::list2(
resembling_offset = wohnflaeche_ro_range,
exact_offset = wohnflaeche_eo_range,
non_list_reason_sensitivity = glue::glue("non_list_reason_{!!exact_offset}")
)
values = rlang::list2(
resembling_offset = wohnflaeche_ro_range,
exact_offset = wohnflaeche_eo_range,
non_list_reason_sensitivity = glue::glue("non_list_reason_{wohnflaeche_eo_range}")
)
values
values = rlang::list2(
resembling_offset = wohnflaeche_ro_range,
exact_offset = wohnflaeche_eo_range,
non_list_reason_sensitivity = glue::glue(
"non_list_reason_{wohnflaeche_eo_range |> str_replace_all('.','_')}")
)
values
values = rlang::list2(
resembling_offset = wohnflaeche_ro_range,
exact_offset = wohnflaeche_eo_range,
non_list_reason_sensitivity = glue::glue(
"non_list_reason_{wohnflaeche_eo_range |> str_replace_all('\\.','_')}")
)
values = rlang::list2(
resembling_offset = wohnflaeche_ro_range,
exact_offset = wohnflaeche_eo_range,
non_list_reason_sensitivity = glue::glue(
"non_list_reason_{wohnflaeche_eo_range |> str_replace_all('\.','_')}")
)
values = rlang::list2(
resembling_offset = wohnflaeche_ro_range,
exact_offset = wohnflaeche_eo_range,
non_list_reason_sensitivity = glue::glue(
"non_list_reason_{wohnflaeche_eo_range |> str_replace_all('\.','_')}")
)
)
values = rlang::list2(
resembling_offset = wohnflaeche_ro_range,
exact_offset = wohnflaeche_eo_range,
non_list_reason_sensitivity = glue::glue(
"non_list_reason_{wohnflaeche_eo_range |> str_replace_all('\\.','_')}")
)
wohnflaeche_eo_range |> str_replace_all('\\.','_')
# ###########################################################################
# # FEDERALSTATE_TARGETS -------------------------------------------------------------
# ###########################################################################
#
## create targets for each federal states
federal_state_targets <- rlang::list2(
#this seems slightly slower than prior usage of tar_group_by + pattern(map)
# usage of pattern causes hash names however which makes loading difficult
# classify data
tar_eval(
tar_fst_dt(
classification_ids,
make_classification(
geo_grouped_data = RED[.(federal_state_ids), on = "blid"]
)
),
values = rlang::list2(
federal_state_ids = federal_state_ids,
classification_ids = classification_ids
)
),
tar_eval(
tar_fst_dt(
non_list_reason_sensitivities,
make_sensitivity(
geo_grouped_data = RED[.(4), on = "blid"],
resembling_offset,
exact_offset
)
),
values = rlang::list2(
resembling_offset = wohnflaeche_ro_range,
exact_offset = wohnflaeche_eo_range,
non_list_reason_sensitivities = glue::glue(
"non_list_reason_{sensitivity_suffix}")
)
)
)
tar_load_globals
tar_load_globals()
str(federal_state_targets)
attr(federal_state_targets)
attributes(federal_state_targets)
names(federal_state_targets)
federal_state_targets
tar_visnetwork()
tar_visnetwork()
tar_make()
tar_load(sensitvity )
summary(sensitvity)
tar_visnetwork()
sensitvity[, .N, by = "wohnflaeche_eo_range"]
sensitvity[, .N, by = c("wohnflaeche_eo_range")]
sensitvity[, .N, by = c("wohnflaeche_e_o")]
sensitvity[, .N, by = c("wohnflaeche_e_o","non_list_reason")]
names(sensitvity)
sensitvity[, .N, by = c("wohnflaeche_e_o","sim_index")]
sensitvity[, .N, by = c("wohnflaeche_e_o","parent")]
sensitvity[, mean(.N), by = c("wohnflaeche_e_o","parent")]
sensitvity[, count("parent"), by = c("wohnflaeche_e_o")]
sensitvity[, count(parent), by = c("wohnflaeche_e_o")]
sensitvity[, .N, by = c("wohnflaeche_e_o","non_list_reason")]
styler:::style_active_file()
styler:::style_active_file()
group_counts <- sensitvity[,
.N,
by = c("wohnflaeche_e_o", "parent")
]
group_counts <- sensitvity[,
.N,
by = c("wohnflaeche_e_o", "parent")
][,
mean("N"),
by = c("wohnflaeche_e_o")
]
group_counts <- sensitvity[,
.N,
by = c("wohnflaeche_e_o", "parent")
][,
mean(N),
by = c("wohnflaeche_e_o")
]
View(group_counts)
styler:::style_active_file()
sensitvity[,
.N,
by = c("wohnflaeche_e_o", "parent")
][,
.(mean(N),
max(N)),
by = c("wohnflaeche_e_o")
]
styler:::style_active_file()
summary_group_sizes <- sensitvity[,
.N,
by = c("wohnflaeche_e_o", "parent")
][,
.(
mean(N),
sd(N),
min(N),
median(N),
max(N),
),
by = c("wohnflaeche_e_o")
]
summary_group_sizes <- sensitvity[,
.N,
by = c("wohnflaeche_e_o", "parent")
][,
.(
"Mean" = mean(N),
sd(N),
min(N),
median(N),
max(N)
),
by = c("wohnflaeche_e_o")
]
summary_group_sizes
summary_group_sizes <- sensitvity[,
.N,
by = c("wohnflaeche_e_o", "parent")
][,
.(
"Mean" = mean(N),
"SD" = sd(N),
"Min" = min(N),
"Med" = median(N),
"Max" = max(N)
),
by = c("wohnflaeche_e_o")
]
summary_group_sizes
summary_group_sizes <- sensitvity[,
.N,
by = c("wohnflaeche_e_o", "parent")
][N>1,
.(
"Mean" = mean(N),
"SD" = sd(N),
"Min" = min(N),
"Med" = median(N),
"Max" = max(N)
),
by = c("wohnflaeche_e_o")
]
summary_group_sizes
styler:::style_active_file()
group_sizes[, .N,
by = c("wohnflaeche_e_o")
]
group_sizes <- sensitvity[,
.N,
by = c("wohnflaeche_e_o", "parent")
]
group_sizes[, .N,
by = c("wohnflaeche_e_o")
]
summary_group_sizes <- group_sizes[,
.(
"Count" = .N,
"Mean" = mean(N),
"SD" = sd(N),
"Min" = min(N),
"Med" = median(N),
"Max" = max(N)
),
by = c("wohnflaeche_e_o")
]
summary_group_sizes
group_sizes |>  tabyl(N)
group_sizes
group_sizes[,
.N,
by= c("wohnflaeche_e_o", "N")]
styler:::style_active_file()
styler:::style_active_file()
styler:::style_active_file()
ggplot(group_counts, aes(x = wohnflaeche_e_o, y = size)) + geom_bar()
group_sizes <- sensitvity[,
.("size" = .N),
by = c("wohnflaeche_e_o", "parent")
]
group_counts <- group_sizes[,
.("counts" = .N),
by = c("wohnflaeche_e_o", "N")
]
ggplot(group_counts, aes(x = wohnflaeche_e_o, y = size)) + geom_bar()
group_sizes <- sensitvity[,
.("size" = .N),
by = c("wohnflaeche_e_o", "parent")
]
group_counts <- group_sizes[,
.("counts" = .N),
by = c("wohnflaeche_e_o", "N")
]
group_counts <- group_sizes[,
.("counts" = .N),
by = c("wohnflaeche_e_o", "size")
]
ggplot(group_counts, aes(x = wohnflaeche_e_o, y = size)) + geom_bar()
ggplot(group_counts, aes(y = size)) + geom_bar()
tst = ggplot(group_counts, aes(y = size)) + geom_bar()
tst
tst = ggplot(group_counts, aes(y = size)) + geom_bar(aes(x = counts))
tst
tst = ggplot(group_counts, aes(size)) + geom_bar()
tst
View(tst)
ggplot(group_counts, aes(size)) + geom_bar()
ggplot(group_counts, aes(size)) + geom_bar()
ggplot(group_counts, aes(size,counts)) + geom_bar()
ggplot(group_counts, aes(x= counts,y = size, fill = wohnflaeche_e_o)) + geom_bar()
ggplot(group_counts, aes(x= "counts", y = "size", fill = "wohnflaeche_e_o")) + geom_bar()
ggplot(group_counts, aes(fill = "wohnflaeche_e_o", x= "counts", y = "size")) + geom_bar(position = "dodge", stat = "identity")
ggplot(group_counts, aes(fill = wohnflaeche_e_o, x= size, y = counts)) + geom_bar(position = "dodge", stat = "identity")
ggplot(group_counts, aes(x = wohnflaeche_e_o, fill= size, y = counts)) + geom_bar(position = "dodge", stat = "identity")
ggplot(group_counts, aes(x = wohnflaeche_e_o, y= size, fill = counts)) + geom_bar(position = "dodge", stat = "identity")
ggplot(group_counts, aes(fill = wohnflaeche_e_o, x= size, y = counts)) + geom_bar(position = "dodge", stat = "identity")
ggplot(group_counts, aes(fill = wohnflaeche_e_o, x= size, y = counts)) + geom_bar(position = "stack", stat = "identity")
ggplot(group_counts, aes(fill = wohnflaeche_e_o, x= size, y = counts)) +
geom_bar(position = "dodge", stat = "identity") +
facet_wrap(~wohnflaeche_e_o)
ggplot(group_counts, aes( x= size, y = counts)) +
geom_bar(position = "dodge", stat = "identity") +
facet_wrap(~wohnflaeche_e_o)
sensitvity[,
.N,
by = c("wohnflaeche_e_o", "non_list_reason")
]
sensitvity |> tabyl(wohnflaeche_e_o,non_list_reason)
sensitvity |>
tabyl(wohnflaeche_e_o,non_list_reason) >
adorn_totals("row") |>
adorn_percentages("row") |>
adorn_pct_formatting(digits = 2) |>
adorn_ns()
sensitvity |>
tabyl(wohnflaeche_e_o,non_list_reason) >
adorn_percentages("row") |>
adorn_pct_formatting(digits = 2) |>
adorn_ns()
sensitvity |>
tabyl(wohnflaeche_e_o,non_list_reason)
sensitvity |>
tabyl(wohnflaeche_e_o,non_list_reason) |>
adorn_totals("row") |>
adorn_percentages("row") |>
adorn_pct_formatting(digits = 2) |>
adorn_ns()
sensitvity |>
tabyl(wohnflaeche_e_o,non_list_reason) |>
adorn_totals("row") |>
adorn_percentages("row")
non_list_reason_perc = sensitvity |>
tabyl(wohnflaeche_e_o,non_list_reason) |>
adorn_totals("row") |>
adorn_percentages("row") |>
adorn_pct_formatting(digits = 2)
ggplot(non_list_reason_perc, aes(wohnflaeche_e_o)) + geom_line()
ggplot(non_list_reason_perc, aes(wohnflaeche_e_o, Miss)) + geom_line()
ggplot(non_list_reason_perc, aes(wohnflaeche_e_o, values)) + geom_line()
ggplot(non_list_reason_perc, aes(x = wohnflaeche_e_o, y = c("Miss","Sold","Update"))) + geom_line()
ggplot(non_list_reason_perc, aes(x = wohnflaeche_e_o, fill = c("Miss","Sold","Update"))) + geom_line()
ggplot(non_list_reason_perc, aes(x = wohnflaeche_e_o, y = Miss)) + geom_line()
ggplot(non_list_reason_perc, aes(x = wohnflaeche_e_o, y = value, group = Miss)) + geom_line()
ggplot(non_list_reason_perc, aes(x = wohnflaeche_e_o, y = Miss)) + geom_line()
ggplot(non_list_reason_perc, aes(x = wohnflaeche_e_o, y = Miss, group = Miss)) + geom_line()
ggplot(non_list_reason_perc, aes(x = wohnflaeche_e_o, y = Miss, fill = Miss)) + geom_line()
ggplot(non_list_reason_perc, aes(x = wohnflaeche_e_o) + geom_line(aes(y = Miss))
group_sizes <- sensitvity[,
.("size" = .N),
by = c("wohnflaeche_e_o", "parent")
]
group_counts <- group_sizes[,
.("counts" = .N),
by = c("wohnflaeche_e_o", "size")
]
# ggplot(group_counts, aes( x= size, y = counts)) +
#   geom_bar(position = "dodge", stat = "identity") +
#   facet_wrap(~wohnflaeche_e_o)
summary_group_sizes <- group_sizes[,
.(
"Count" = .N,
"Mean" = mean(size),
"SD" = sd(size),
"Min" = min(size),
"Med" = median(size),
"Max" = max(size)
),
by = c("wohnflaeche_e_o")
]
}
ggplot(non_list_reason_perc, aes(x = wohnflaeche_e_o)) + geom_line(aes(y = Miss))
ggplot(non_list_reason_perc, aes(x = wohnflaeche_e_o)) +
geom_line(aes(y = Miss, color = "Miss"), lwd = 0.8) +
geom_line(aes(y = Sold, color = "Sold"), lwd = 0.8) +
geom_line(aes(y = Update, color = "Update"), lwd = 0.8)
non_list_reason_perc = sensitvity |>
tabyl(wohnflaeche_e_o,non_list_reason) |>
adorn_totals("row") |>
adorn_percentages("row") |>
adorn_pct_formatting(digits = 2)
non_list_reason_perc
tar_load(classification)
classification = classification["Sold", ln_pvar = log(price_var), on = "non_list_reason"]
classification = classification["Sold", ln_pvar := log(price_var), on = "non_list_reason"]
head(classification)
classification = classification["Sold", on = "non_list_reason"]
classification = classification["Sold", on = "non_list_reason"][,ln_pvar := log(price_var)]
summary(classification$ln_pvar)
summary(classification$price_var)
# repeated sales regression
first_percentile = quantile(classification[,pvar],1-(0.5/100))
# repeated sales regression
first_percentile = quantile(classification[price_var>=0,price_var],1-(0.5/100))
last_percentile = quantile(classification[price_var>=0,price_var],(0.5/100))
classification = classification["Sold", on = "non_list_reason"][price_var<= last_percentile & price_var>= first_percentile]
styler:::style_active_file()
styler:::style_active_file()
classification[price_var >= 0, price_var]
str(classification$price_var)
tar_load(classification)
classification <- classification[
"Sold",
on = "non_list_reason"
]
first_percentile <- quantile(classification[price_var >= 0, price_var], 1 - (0.5 / 100))
last_percentile <- quantile(classification[price_var >= 0, price_var], (0.5 / 100))
tst = classification[price_var <= upper_percentile & price_var >= lower_percentile]
tst = classification["price_var" <= upper_percentile & "price_var" >= lower_percentile]
upper_percentile
upper_percentile <- quantile(classification[price_var >= 0, price_var], 1 - (0.5 / 100))
lower_percentile <- quantile(classification[price_var >= 0, price_var], (0.5 / 100))
tst = classification[price_var <= upper_percentile & price_var >= lower_percentile]
tst = classification[price_var <= upper_percentile & price_var >= lower_percentile, ln_pvar = log(price_var)]
tst = classification[price_var <= upper_percentile & price_var >= lower_percentile, ln_pvar := log(price_var)]
styler:::style_active_file()
