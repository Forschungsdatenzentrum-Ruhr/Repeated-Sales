summary_skim_cat,
datasummary_skim_categorical(
classification
)
),
tar_eval(
tar_target(
target_name,
custom_cross_tabyl(
classification,
arg1 = arg1,
arg2 = arg2
)
),
values = cross_tabyl_arguments
),
# tar_target(
#   summary_threeway,
#   custom_threeway_tabyl(
#     classification,
#     "blid",
#     "same_time_listing",
#     "non_list_reason"
#   )
# )
tar_target(
summary_threeway,
custom_cross_tabyl(
classification,
"blid",
"same_time_listing"
)
),
# sensitivity
tar_target(
summary_sensitivity,
summary_graph_sensitivity(
sensitivity
)
),
# Figures -----------------------------------------------------------------
)
###########################################################################
# EXPORT-TARGETS -----------------------------------------------------------
###########################################################################
export_targets <- rlang::list2(
tar_target(
export_classification,
export_data(
classification,
file_name
)
),
)
###########################################################################
# FINAL_TARGETS -----------------------------------------------------------
###########################################################################
## combine to main pipeline
rlang::list2(
file_targets,
# federal state targets
federal_state_targets,
# # combine last step of federal state targets together into single output
tar_combine(
classification,
federal_state_targets[[1]],
command = bind_rows(!!!.x),
format = "fst_dt"
),
# # combine last step of federal state targets together into single output
tar_combine(
sensitivity,
federal_state_targets[[length(federal_state_targets)]],
command = bind_rows(!!!.x),
format = "fst_dt"
),
#summary_targets,
export_targets
)
###########################################################################
# PLOTTING ----------------------------------------------------------------
###########################################################################
tar_load(RED)
geo_grouped_data = RED |> filter(latlon_utm == "5914872.28545209603584.936611244")
# extract ids and combinations of non-duplicates
occurence_ids <- geo_grouped_data[, counting_id]
# does order matter here? key = amonths?
combinations <- geo_grouped_data[, ..categories]
# make copy to modifiy keys
geo_grouped_data = copy(geo_grouped_data)
setkey(geo_grouped_data, wohnflaeche, etage, zimmeranzahl)
similarity_index_list <- similarity_dist_list <- list()
if(!nrow(combinations) == 1){
# increase etage by one to avoid scaling around 0
combinations[, etage := etage + 1]
## similiarity calculations
for (i in 1:nrow(combinations)) {
# percentage of rooms scaled values are allowed to be off
# e.g. what percentage of 8 rooms is 0.5 rooms
# this feels way to complicated
scaled_zimmeranzahl_r_o <- combinations[
,
(as.numeric(combinations[i, "zimmeranzahl"]) + zimmeranzahl_r_o) / as.numeric(combinations[i, "zimmeranzahl"]) - 1
]
# scaling around 0 causes div by 0 and inf for everything else
# just increase etage by one? other solution?
data_to_similarity <- scale(combinations, center = F, scale = combinations[i]) |> as.data.table()
similarity_index_list[[i]] <- data_to_similarity[
,
.(fcase(
## exact repeat [small percentage deviation acceptable]
abs(1 - wohnflaeche) <= wohnflaeche_e_o &
# zimmeranzahl and etage are exact matches
zimmeranzahl == 1 &
etage == 1,
0,
## similar repeat [larger percentage deviation acceptable]
abs(1 - wohnflaeche) <= wohnflaeche_r_o &
# zimmeranzahl deviation acceptable / etage arbitrary
abs(1 - zimmeranzahl) <= scaled_zimmeranzahl_r_o &
# etage exact match
etage == 1,
1,
# no matches
default = NA
))
] |> as.matrix()
similarity_dist_list[[i]] <- as.matrix(dist(data_to_similarity, method = "euclidean"))[i, ]
}
## clustering
# transform to data.tables and set counting ids as column names
similarity_dist_list <- as.data.table(similarity_dist_list)
similarity_index_list <- as.data.table(similarity_index_list)
# enforce zero diagonal(allows classification of zero observations which otherwise are fully NA)
diag(similarity_index_list) = 0
setnames(similarity_index_list, as.character(occurence_ids))
setnames(similarity_dist_list, as.character(occurence_ids))
# setup and run the actual clustering
clustering <- cluster$new(
cluster_options = similarity_index_list,
distance = similarity_dist_list,
means = rowMeans(similarity_index_list * similarity_dist_list, na.rm = T)
)
clustering$determine_cluster_centers()
if (anyDuplicated(clustering$centers$counting_id)) {
# filter/fix duplicates within $centers here if they exist
# currently its always being parents > being a child to ease calc
# otherwise there has to be a cost assigned for non-parenthood
# can prob just compare sim_dist to parent (gain from being child) vs
# sum(sim_dist) to children (gain from being parent/cost)
clustering$centers <- clustering$centers[
,
similarity_cost_function(.SD)
]
}
} else {
# this could be function since im doing it more than once
# does this make the if within cluster-class irrelevant?
clustering <- cluster$new(
cluster_options = NULL
)
clustering$centers = data.table(
"counting_id" = as.numeric(occurence_ids),
"parent" = as.numeric(occurence_ids),
"sim_dist" = 0,
"sim_index" = 0
)
}
# setup and run the actual clustering
clustering <- cluster$new(
cluster_options = similarity_index_list,
distance = similarity_dist_list,
means = rowMeans(similarity_index_list * similarity_dist_list, na.rm = T)
)
clustering$determine_cluster_centers()
clustering_centers = clustering$centers
# unique deals with a parent being chosen as such from multiple cluster
# since the parent is the same either way, no special consideration is necessary
unique_clustering_centers <- unique(clustering_centers)
View(unique_clustering_centers)
# keep only non-NAs for further considerations
unique_clustering_centers <- unique_clustering_centers[
!is.na(sim_index)
]
# isolate cases where conflicts arose
competing_parents <- unique_clustering_centers[
,
.SD[.N >= 2],
by = "counting_id"
]
View(competing_parents)
View(unique_clustering_centers)
# x is potential child of y or z but not itself -> choose lowest sim_dist
# this also contains all listings with are their own parent -> used in first option
parent_parent_competitors <- competing_parents[
,
.SD[which.min(sim_dist)],
by = "counting_id"
]
# isolate cases where there was pure parent vs parent competition
# this likely influences parent vs children competition and should be remerged to initial data
parent_parent_winners <- parent_parent_competitors[
parent != counting_id
]
View(parent_parent_winners)
# find parents which have conflicting classifications
parent_children_ids <- parent_parent_competitors[
parent == counting_id
]$parent
if (length(parent_children_ids) != 0) {
## first option: x parent of cluster x with children y_n -> gain = sum(similiarity of children)
# isolate competitors based on ids
parent_children_competitors <- unique_clustering_centers[
.(parent_children_ids),
on = "parent"
]
# calculate gains of being x being a parent
parent_gains <- parent_children_competitors[
,
.("cluster_sim_dist" = sum(sim_dist)),
by = "parent",
]
## second option: x child of cluster z -> gain = similarity to parent
# isolate competitors based on ids
child_parent_competitors <- unique_clustering_centers[
.(parent_children_ids),
on = "counting_id"
]
child_gains <- child_parent_competitors[
!.(parent_children_ids),
.("counting_id" = counting_id, "single_sim_dist" = sim_dist),
on = "parent"
]
# Compare gains
gains_comparison <- parent_gains[
child_gains,
"winner" := fifelse(
cluster_sim_dist >= single_sim_dist, "parent", "child"
),
on = .(parent == counting_id)
]
}
tar_make()
tar_make()
tar_make()
tar_make()
tar_make()
tar_make()
tar_make()
RED |> filter(counting_id == "64924") |> select(latlon_utm)
# parent_child Example
geo_grouped_data = RED |> filter(latlon_utm == "5915033.15972125602782.786688613")
View(geo_grouped_data)
# extract ids and combinations of non-duplicates
occurence_ids <- geo_grouped_data[, counting_id]
# does order matter here? key = amonths?
combinations <- geo_grouped_data[, ..categories]
# make copy to modifiy keys
geo_grouped_data = copy(geo_grouped_data)
setkey(geo_grouped_data, wohnflaeche, etage, zimmeranzahl)
similarity_index_list <- similarity_dist_list <- list()
if(!nrow(combinations) == 1){
# increase etage by one to avoid scaling around 0
combinations[, etage := etage + 1]
## similiarity calculations
for (i in 1:nrow(combinations)) {
# percentage of rooms scaled values are allowed to be off
# e.g. what percentage of 8 rooms is 0.5 rooms
# this feels way to complicated
scaled_zimmeranzahl_r_o <- combinations[
,
(as.numeric(combinations[i, "zimmeranzahl"]) + zimmeranzahl_r_o) / as.numeric(combinations[i, "zimmeranzahl"]) - 1
]
# scaling around 0 causes div by 0 and inf for everything else
# just increase etage by one? other solution?
data_to_similarity <- scale(combinations, center = F, scale = combinations[i]) |> as.data.table()
similarity_index_list[[i]] <- data_to_similarity[
,
.(fcase(
## exact repeat [small percentage deviation acceptable]
abs(1 - wohnflaeche) <= wohnflaeche_e_o &
# zimmeranzahl and etage are exact matches
zimmeranzahl == 1 &
etage == 1,
0,
## similar repeat [larger percentage deviation acceptable]
abs(1 - wohnflaeche) <= wohnflaeche_r_o &
# zimmeranzahl deviation acceptable / etage arbitrary
abs(1 - zimmeranzahl) <= scaled_zimmeranzahl_r_o &
# etage exact match
etage == 1,
1,
# no matches
default = NA
))
] |> as.matrix()
similarity_dist_list[[i]] <- as.matrix(dist(data_to_similarity, method = "euclidean"))[i, ]
}
## clustering
# transform to data.tables and set counting ids as column names
similarity_dist_list <- as.data.table(similarity_dist_list)
similarity_index_list <- as.data.table(similarity_index_list)
# enforce zero diagonal(allows classification of zero observations which otherwise are fully NA)
diag(similarity_index_list) = 0
setnames(similarity_index_list, as.character(occurence_ids))
setnames(similarity_dist_list, as.character(occurence_ids))
# setup and run the actual clustering
clustering <- cluster$new(
cluster_options = similarity_index_list,
distance = similarity_dist_list,
means = rowMeans(similarity_index_list * similarity_dist_list, na.rm = T)
)
clustering$determine_cluster_centers()
if (anyDuplicated(clustering$centers$counting_id)) {
# filter/fix duplicates within $centers here if they exist
# currently its always being parents > being a child to ease calc
# otherwise there has to be a cost assigned for non-parenthood
# can prob just compare sim_dist to parent (gain from being child) vs
# sum(sim_dist) to children (gain from being parent/cost)
clustering$centers <- clustering$centers[
,
similarity_cost_function(.SD)
]
}
} else {
# this could be function since im doing it more than once
# does this make the if within cluster-class irrelevant?
clustering <- cluster$new(
cluster_options = NULL
)
clustering$centers = data.table(
"counting_id" = as.numeric(occurence_ids),
"parent" = as.numeric(occurence_ids),
"sim_dist" = 0,
"sim_index" = 0
)
}
# setup and run the actual clustering
clustering <- cluster$new(
cluster_options = similarity_index_list,
distance = similarity_dist_list,
means = rowMeans(similarity_index_list * similarity_dist_list, na.rm = T)
)
clustering$determine_cluster_centers()
clustering_centers = clustering$centers
# unique deals with a parent being chosen as such from multiple cluster
# since the parent is the same either way, no special consideration is necessary
unique_clustering_centers <- unique(clustering_centers)
# keep only non-NAs for further considerations
unique_clustering_centers <- unique_clustering_centers[
!is.na(sim_index)
]
View(unique_clustering_centers)
# isolate cases where conflicts arose
competing_parents <- unique_clustering_centers[
,
.SD[.N >= 2],
by = "counting_id"
]
View(competing_parents)
# x is potential child of y or z but not itself -> choose lowest sim_dist
# this also contains all listings with are their own parent -> used in first option
parent_parent_competitors <- competing_parents[
,
.SD[which.min(sim_dist)],
by = "counting_id"
]
# isolate cases where there was pure parent vs parent competition
# this likely influences parent vs children competition and should be remerged to initial data
parent_parent_winners <- parent_parent_competitors[
parent != counting_id
]
View(parent_parent_winners)
View(geo_grouped_data)
View(parent_parent_competitors)
View(competing_parents)
# find parents which have conflicting classifications
parent_children_ids <- parent_parent_competitors[
parent == counting_id
]$parent
## first option: x parent of cluster x with children y_n -> gain = sum(similiarity of children)
# isolate competitors based on ids
parent_children_competitors <- unique_clustering_centers[
.(parent_children_ids),
on = "parent"
]
View(parent_children_competitors)
# calculate gains of being x being a parent
parent_gains <- parent_children_competitors[
,
.("cluster_sim_dist" = sum(sim_dist)),
by = "parent",
]
View(parent_gains)
## second option: x child of cluster z -> gain = similarity to parent
# isolate competitors based on ids
child_parent_competitors <- unique_clustering_centers[
.(parent_children_ids),
on = "counting_id"
]
View(child_parent_competitors)
child_gains <- child_parent_competitors[
!.(parent_children_ids),
.("counting_id" = counting_id, "single_sim_dist" = sim_dist),
on = "parent"
]
View(child_gains)
# Compare gains
gains_comparison <- parent_gains[
child_gains,
"winner" := fifelse(
cluster_sim_dist >= single_sim_dist, "parent", "child"
),
on = .(parent == counting_id)
]
View(gains_comparison)
for(winner in gains_comparison){
print(winner)
}
for(winner in nrow(gains_comparison)){
print(winner)
}
for(curr_winner in nrow(gains_comparison)){
gains_comparison[winner]
}
for(curr_winner in nrow(gains_comparison)){
gains_comparison[curr_winner]
}
print(gains_comparison[curr_winner])
View(parent_gains)
View(child_gains)
# calculate gains of being x being a parent
parent_gains <- parent_children_competitors[
,
.("cluster_sim_dist" = mean(sim_dist)),
by = "parent",
]
## second option: x child of cluster z -> gain = similarity to parent
# isolate competitors based on ids
child_parent_competitors <- unique_clustering_centers[
.(parent_children_ids),
on = "counting_id"
]
child_gains <- child_parent_competitors[
!.(parent_children_ids),
.("counting_id" = counting_id, "single_sim_dist" = sim_dist),
on = "parent"
]
# Compare gains and choose
gains_comparison <- parent_gains[
child_gains,
"winner_type" := fifelse(
cluster_sim_dist >= single_sim_dist, "parent", "child"
),
on = .(parent == counting_id)
]
# Compare gains and choose lower sim_dist (more similiarity gained)
gains_comparison <- parent_gains[
child_gains,
"winner_type" = fifelse(
cluster_sim_dist >= single_sim_dist, "child", "parent"
),
on = .(parent == counting_id)
]
# Compare gains and choose lower sim_dist (more similiarity gained)
gains_comparison <- parent_gains[
child_gains,
.("winner_type" = fifelse(
cluster_sim_dist >= single_sim_dist, "child", "parent"
)
),
on = .(parent == counting_id)
]
gains_comparison
styler:::style_active_file()
styler:::style_active_file()
# Compare gains and choose lower sim_dist (more similiarity gained)
gains_comparison <- parent_gains[
child_gains,
.(
"counting_id" = counting_id,
"winner_type" = fifelse(
cluster_sim_dist >= single_sim_dist, "child", "parent"
)
),
on = .(parent == counting_id)
]
View(gains_comparison)
?split
tst = split(gains_comparison, winner_type)
tst = split(gains_comparison, "winner_type")
View(tst)
View(tst)
winner_ids = split(gains_comparison, "winner_type")
clustering_centers
winner_ids = split(gains_comparison, "winner_type", flatten = F)
View(winner_ids)
winner_ids = split(gains_comparison, "winner_type", flatten = F, keep.by = F)
View(winner_ids)
winner_ids = split(gains_comparison, "winner_type", keep.by = F)
View(winner_ids)
gains_comparison = rbind(gains_comparison,gains_comparison)
View(gains_comparison)
gains_comparison[2]
gains_comparison[2,2] = "child"
winner_ids = split(gains_comparison, "winner_type", keep.by = F)
View(winner_ids)
winner_ids = split(gains_comparison, "winner_type", keep.by = T)
winner_ids = split(gains_comparison, by = "winner_type", keep.by = T)
View(winner_ids)
winner_ids = split(gains_comparison, by = "winner_type", keep.by = F)
View(winner_ids)
